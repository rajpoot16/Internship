{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1c6a8435",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57953484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd36ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f31c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1=[]\n",
    "r1=driver.find_element(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr[1]')\n",
    "row_1.append(r1.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6792d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.',\n",
       "  '\"Baby',\n",
       "  'Shark',\n",
       "  'Dance\"[3]',\n",
       "  'Pinkfong',\n",
       "  'Baby',\n",
       "  'Shark',\n",
       "  '-',\n",
       "  \"Kids'\",\n",
       "  'Songs',\n",
       "  '&',\n",
       "  'Stories',\n",
       "  '11.30',\n",
       "  'June',\n",
       "  '17,',\n",
       "  '2016',\n",
       "  '[A]']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a67d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "04a86bfe",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0f4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2144acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044a0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'//button[@class=\"navbar-toggler menu-btn menu-icon\"]')\n",
    "c1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3fc333",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2=driver.find_element(By.XPATH,'//li[@class=\"nav-item\"]')\n",
    "c2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69bc0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_title=[]\n",
    "match=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in match:\n",
    "    m=i.text\n",
    "    match_title.append(m)\n",
    "\n",
    "series=[]\n",
    "s=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in s:\n",
    "    s1=i.text\n",
    "    series.append(s1)\n",
    "\n",
    "place=[]\n",
    "p=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in p:\n",
    "    p1=i.text.split()[4:]\n",
    "    place.append(p1)\n",
    "    \n",
    "date=[]\n",
    "d=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "for i in d:\n",
    "    d1=i.text\n",
    "    date.append(d1)\n",
    "    \n",
    "time=[]\n",
    "t=driver.find_elements(By.XPATH,'//div[@class=\"match-card-right match-schedule \"]')\n",
    "for i in t:\n",
    "    t1=i.text\n",
    "    time.append(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a101a844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(match_title),len(series),len(place),len(date),len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02a1b056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>[Ground,, Derby]</td>\n",
       "      <td>13 SEP 2022</td>\n",
       "      <td>10:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>[Ground,, Bristol]</td>\n",
       "      <td>15 SEP 2022</td>\n",
       "      <td>11:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>[Ground,, Hove]</td>\n",
       "      <td>18 SEP 2022</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>[Cricket, Association, IS, Bindra, Stadium,, M...</td>\n",
       "      <td>20 SEP 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>[Lawrence, Ground,, Canterbury]</td>\n",
       "      <td>21 SEP 2022</td>\n",
       "      <td>5:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>[Cricket, Association, Stadium,, Nagpur]</td>\n",
       "      <td>23 SEP 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>[Cricket, Ground,, London]</td>\n",
       "      <td>24 SEP 2022</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>[Gandhi, International, Stadium,, Hyderabad]</td>\n",
       "      <td>25 SEP 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                                       Series  \\\n",
       "0  2nd T20I -  INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022   \n",
       "1  3rd T20I -  INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022   \n",
       "2   1st ODI -  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   \n",
       "3  1st T20I -      AUSTRALIA TOUR OF INDIA T20 SERIES 2022   \n",
       "4   2nd ODI -  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   \n",
       "5  2nd T20I -      AUSTRALIA TOUR OF INDIA T20 SERIES 2022   \n",
       "6   3rd ODI -  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   \n",
       "7  3rd T20I -      AUSTRALIA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                               Place         Date  \\\n",
       "0                                   [Ground,, Derby]  13 SEP 2022   \n",
       "1                                 [Ground,, Bristol]  15 SEP 2022   \n",
       "2                                    [Ground,, Hove]  18 SEP 2022   \n",
       "3  [Cricket, Association, IS, Bindra, Stadium,, M...  20 SEP 2022   \n",
       "4                    [Lawrence, Ground,, Canterbury]  21 SEP 2022   \n",
       "5           [Cricket, Association, Stadium,, Nagpur]  23 SEP 2022   \n",
       "6                         [Cricket, Ground,, London]  24 SEP 2022   \n",
       "7       [Gandhi, International, Stadium,, Hyderabad]  25 SEP 2022   \n",
       "\n",
       "           Time  \n",
       "0  10:30 PM IST  \n",
       "1  11:00 PM IST  \n",
       "2   3:30 PM IST  \n",
       "3   7:30 PM IST  \n",
       "4   5:30 PM IST  \n",
       "5   7:30 PM IST  \n",
       "6   3:30 PM IST  \n",
       "7   7:30 PM IST  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Match Title':match_title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce9f3fca",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e84ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0f4f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b209ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'//a[@data-lasso-id=\"147434\"]')\n",
    "c1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36732eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2=driver.find_element(By.XPATH,'//a[@data-lasso-id=\"182688\"]')\n",
    "c2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2850d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1=[]\n",
    "n1=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]')\n",
    "for i in n1:\n",
    "    n11=i.text.split()\n",
    "    name1.append(n11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce9c9365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.', 'ElementNotVisibleException:']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_name1=name1[0][:2]\n",
    "new_name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac980fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'type',\n",
       " 'of',\n",
       " 'Selenium',\n",
       " 'exception',\n",
       " 'occurs',\n",
       " 'when',\n",
       " 'an',\n",
       " 'existing',\n",
       " 'element',\n",
       " 'in',\n",
       " 'DOM',\n",
       " 'has',\n",
       " 'a',\n",
       " 'feature',\n",
       " 'set',\n",
       " 'as',\n",
       " 'hidden.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description1=name1[0][2:]\n",
    "description1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0ab8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name2=[]\n",
    "n2=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[2]')\n",
    "name2.append(n2.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbf78c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.', 'ElementNotSelectableException:']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_name2=name2[0][:2]\n",
    "new_name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cf10352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Selenium',\n",
       " 'exception',\n",
       " 'occurs',\n",
       " 'when',\n",
       " 'an',\n",
       " 'element',\n",
       " 'is',\n",
       " 'presented',\n",
       " 'in',\n",
       " 'the',\n",
       " 'DOM,',\n",
       " 'but',\n",
       " 'you',\n",
       " 'can',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'select.',\n",
       " 'Therefore,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'interact.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description2=name2[0][2:]\n",
    "description2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29db381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.', 'NoSuchElementException:']\n",
      "['This', 'Exception', 'occurs', 'if', 'an', 'element', 'could', 'not', 'be', 'found.']\n"
     ]
    }
   ],
   "source": [
    "name3=[]\n",
    "n3=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[3]')\n",
    "name3.append(n3.text.split())\n",
    "\n",
    "new_name3=name3[0][:2]\n",
    "print(new_name3)\n",
    "description3=name3[0][2:]\n",
    "print(description3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddc5be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.', 'NoSuchFrameException:']\n",
      "['This', 'Exception', 'occurs', 'if', 'the', 'frame', 'target', 'to', 'be', 'switched', 'to', 'does', 'not', 'exist.']\n"
     ]
    }
   ],
   "source": [
    "name4=[]\n",
    "n4=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[4]')\n",
    "name4.append(n4.text.split())\n",
    "\n",
    "new_name4=name4[0][:2]\n",
    "print(new_name4)\n",
    "description4=name4[0][2:]\n",
    "print(description4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "929889e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.', 'NoAlertPresentException:']\n",
      "['This', 'Exception', 'occurs', 'when', 'you', 'switch', 'to', 'no', 'presented', 'alert.']\n"
     ]
    }
   ],
   "source": [
    "name5=[]\n",
    "n5=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[5]')\n",
    "name5.append(n5.text.split())\n",
    "\n",
    "new_name5=name5[0][:2]\n",
    "print(new_name5)\n",
    "description5=name5[0][2:]\n",
    "print(description5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2e2ccb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.', 'ElementNotVisibleException:'],\n",
       " ['2.', 'ElementNotSelectableException:'],\n",
       " ['3.', 'NoSuchElementException:'],\n",
       " ['4.', 'NoSuchFrameException:'],\n",
       " ['5.', 'NoAlertPresentException:']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Names=[new_name1]+[new_name2]+[new_name3]+[new_name4]+[new_name5]\n",
    "Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b788248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This',\n",
       "  'type',\n",
       "  'of',\n",
       "  'Selenium',\n",
       "  'exception',\n",
       "  'occurs',\n",
       "  'when',\n",
       "  'an',\n",
       "  'existing',\n",
       "  'element',\n",
       "  'in',\n",
       "  'DOM',\n",
       "  'has',\n",
       "  'a',\n",
       "  'feature',\n",
       "  'set',\n",
       "  'as',\n",
       "  'hidden.'],\n",
       " ['This',\n",
       "  'Selenium',\n",
       "  'exception',\n",
       "  'occurs',\n",
       "  'when',\n",
       "  'an',\n",
       "  'element',\n",
       "  'is',\n",
       "  'presented',\n",
       "  'in',\n",
       "  'the',\n",
       "  'DOM,',\n",
       "  'but',\n",
       "  'you',\n",
       "  'can',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'select.',\n",
       "  'Therefore,',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'possible',\n",
       "  'to',\n",
       "  'interact.'],\n",
       " ['This',\n",
       "  'Exception',\n",
       "  'occurs',\n",
       "  'if',\n",
       "  'an',\n",
       "  'element',\n",
       "  'could',\n",
       "  'not',\n",
       "  'be',\n",
       "  'found.'],\n",
       " ['This',\n",
       "  'Exception',\n",
       "  'occurs',\n",
       "  'if',\n",
       "  'the',\n",
       "  'frame',\n",
       "  'target',\n",
       "  'to',\n",
       "  'be',\n",
       "  'switched',\n",
       "  'to',\n",
       "  'does',\n",
       "  'not',\n",
       "  'exist.'],\n",
       " ['This',\n",
       "  'Exception',\n",
       "  'occurs',\n",
       "  'when',\n",
       "  'you',\n",
       "  'switch',\n",
       "  'to',\n",
       "  'no',\n",
       "  'presented',\n",
       "  'alert.']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Description=[description1]+[description2]+[description3]+[description4]+[description5]\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42d2c9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1., ElementNotVisibleException:]</td>\n",
       "      <td>[This, type, of, Selenium, exception, occurs, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2., ElementNotSelectableException:]</td>\n",
       "      <td>[This, Selenium, exception, occurs, when, an, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3., NoSuchElementException:]</td>\n",
       "      <td>[This, Exception, occurs, if, an, element, cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4., NoSuchFrameException:]</td>\n",
       "      <td>[This, Exception, occurs, if, the, frame, targ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5., NoAlertPresentException:]</td>\n",
       "      <td>[This, Exception, occurs, when, you, switch, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "0     [1., ElementNotVisibleException:]   \n",
       "1  [2., ElementNotSelectableException:]   \n",
       "2         [3., NoSuchElementException:]   \n",
       "3           [4., NoSuchFrameException:]   \n",
       "4        [5., NoAlertPresentException:]   \n",
       "\n",
       "                                         Description  \n",
       "0  [This, type, of, Selenium, exception, occurs, ...  \n",
       "1  [This, Selenium, exception, occurs, when, an, ...  \n",
       "2  [This, Exception, occurs, if, an, element, cou...  \n",
       "3  [This, Exception, occurs, if, the, frame, targ...  \n",
       "4  [This, Exception, occurs, when, you, switch, t...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':Names,'Description':Description})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15e31114",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a75ffbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59dd4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7569efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button/i')\n",
    "c1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "628969f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "c2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c352d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "c3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97f8f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "r1=driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')\n",
    "for i in r1[0:33]:\n",
    "    r11=i.text.split()\n",
    "    rank.append(r11)\n",
    "    \n",
    "state=[]\n",
    "s1=driver.find_elements(By.XPATH,'//td[@class=\"name\"]')\n",
    "for i in s1[0:33]:\n",
    "    s11=i.text.split()\n",
    "    state.append(s11)\n",
    "\n",
    "GSDP_18_19=[]\n",
    "g18=driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]')\n",
    "for i in g18[0:33]:\n",
    "    g19=i.text.split()\n",
    "    GSDP_18_19.append(g19)\n",
    "    \n",
    "GSDP_list=[]\n",
    "l1=driver.find_elements(By.XPATH,'//td[@class=\"data\"]')\n",
    "for i in l1[0:165]:\n",
    "    l11=i.text.split()\n",
    "    GSDP_list.append(l11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ea4a7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-'],\n",
       " ['13.94%'],\n",
       " ['399.921'],\n",
       " ['-'],\n",
       " ['2,039,074'],\n",
       " ['1,845,853'],\n",
       " ['8.63%'],\n",
       " ['247.629'],\n",
       " ['1,312,929'],\n",
       " ['1,215,307'],\n",
       " ['1,687,818'],\n",
       " ['8.39%'],\n",
       " ['240.726'],\n",
       " ['1,166,817'],\n",
       " ['1,123,982'],\n",
       " ['-'],\n",
       " ['7.96%'],\n",
       " ['228.290'],\n",
       " ['-'],\n",
       " ['1,186,379'],\n",
       " ['1,631,977'],\n",
       " ['7.91%'],\n",
       " ['226.806'],\n",
       " ['1,156,039'],\n",
       " ['1,091,077'],\n",
       " ['1,253,832'],\n",
       " ['5.77%'],\n",
       " ['165.556'],\n",
       " ['793,223'],\n",
       " ['739,525'],\n",
       " ['1,020,989'],\n",
       " ['4.99%'],\n",
       " ['143.179'],\n",
       " ['711,627'],\n",
       " ['677,428'],\n",
       " ['972,782'],\n",
       " ['4.57%'],\n",
       " ['131.083'],\n",
       " ['672,018'],\n",
       " ['621,301'],\n",
       " ['969,604'],\n",
       " ['4.56%'],\n",
       " ['130.791'],\n",
       " ['663,258'],\n",
       " ['612,828'],\n",
       " ['906,672'],\n",
       " ['4.29%'],\n",
       " ['122.977'],\n",
       " ['561,801'],\n",
       " ['522,009'],\n",
       " ['-'],\n",
       " ['4.14%'],\n",
       " ['118.733'],\n",
       " ['-'],\n",
       " ['559,412'],\n",
       " ['856,112'],\n",
       " ['4.10%'],\n",
       " ['117.703'],\n",
       " ['634,408'],\n",
       " ['590,569'],\n",
       " ['831,610'],\n",
       " ['3.89%'],\n",
       " ['111.519'],\n",
       " ['572,240'],\n",
       " ['531,085'],\n",
       " ['611,804'],\n",
       " ['2.81%'],\n",
       " ['80.562'],\n",
       " ['414,977'],\n",
       " ['375,651'],\n",
       " ['574,760'],\n",
       " ['2.79%'],\n",
       " ['79.957'],\n",
       " ['418,868'],\n",
       " ['397,669'],\n",
       " ['521,275'],\n",
       " ['2.58%'],\n",
       " ['74.098'],\n",
       " ['396,499'],\n",
       " ['376,877'],\n",
       " ['-'],\n",
       " ['1.67%'],\n",
       " ['47.982'],\n",
       " ['-'],\n",
       " ['234,048'],\n",
       " ['329,180'],\n",
       " ['1.61%'],\n",
       " ['46.187'],\n",
       " ['243,477'],\n",
       " ['231,182'],\n",
       " ['328,598'],\n",
       " ['1.57%'],\n",
       " ['45.145'],\n",
       " ['240,036'],\n",
       " ['224,986'],\n",
       " ['-'],\n",
       " ['1.30%'],\n",
       " ['37.351'],\n",
       " ['-'],\n",
       " ['193,273'],\n",
       " ['-'],\n",
       " ['0.83%'],\n",
       " ['23.690'],\n",
       " ['-'],\n",
       " ['112,755'],\n",
       " ['165,472'],\n",
       " ['0.81%'],\n",
       " ['23.369'],\n",
       " ['124,403'],\n",
       " ['117,851'],\n",
       " ['80,449'],\n",
       " ['0.39%'],\n",
       " ['11.115'],\n",
       " ['63,408'],\n",
       " ['57,787'],\n",
       " ['55,984'],\n",
       " ['0.26%'],\n",
       " ['7.571'],\n",
       " ['40,583'],\n",
       " ['36,963'],\n",
       " ['-'],\n",
       " ['0.22%'],\n",
       " ['6.397'],\n",
       " ['-'],\n",
       " ['31,192'],\n",
       " ['38,253'],\n",
       " ['0.18%'],\n",
       " ['5.230'],\n",
       " ['25,093'],\n",
       " ['23,013'],\n",
       " ['36,572'],\n",
       " ['0.18%'],\n",
       " ['5.086'],\n",
       " ['26,695'],\n",
       " ['24,682'],\n",
       " ['32,496'],\n",
       " ['0.15%'],\n",
       " ['4.363'],\n",
       " ['20,017'],\n",
       " ['18,722'],\n",
       " ['31,790'],\n",
       " ['0.15%'],\n",
       " ['4.233'],\n",
       " ['20,673'],\n",
       " ['19,300'],\n",
       " ['-'],\n",
       " ['0.14%'],\n",
       " ['4.144'],\n",
       " ['-'],\n",
       " ['17,647'],\n",
       " ['-'],\n",
       " ['0.13%'],\n",
       " ['3.737'],\n",
       " ['-'],\n",
       " ['16,676'],\n",
       " ['26,503'],\n",
       " ['0.12%'],\n",
       " ['3.385'],\n",
       " ['18,797'],\n",
       " ['16,478'],\n",
       " ['-'],\n",
       " ['-'],\n",
       " ['-'],\n",
       " ['-'],\n",
       " ['-']]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b952dd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-'],\n",
       " ['1,845,853'],\n",
       " ['1,687,818'],\n",
       " ['-'],\n",
       " ['1,631,977'],\n",
       " ['1,253,832'],\n",
       " ['1,020,989'],\n",
       " ['972,782'],\n",
       " ['969,604'],\n",
       " ['906,672'],\n",
       " ['-'],\n",
       " ['856,112'],\n",
       " ['831,610'],\n",
       " ['611,804'],\n",
       " ['574,760'],\n",
       " ['521,275'],\n",
       " ['-'],\n",
       " ['329,180'],\n",
       " ['328,598'],\n",
       " ['-'],\n",
       " ['-'],\n",
       " ['165,472'],\n",
       " ['80,449'],\n",
       " ['55,984'],\n",
       " ['-'],\n",
       " ['38,253'],\n",
       " ['36,572'],\n",
       " ['32,496'],\n",
       " ['31,790'],\n",
       " ['-'],\n",
       " ['-'],\n",
       " ['26,503'],\n",
       " ['-']]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP_19_20=GSDP_list[0:165:5]\n",
    "GSDP_19_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "461a5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['13.94%'],\n",
       " ['8.63%'],\n",
       " ['8.39%'],\n",
       " ['7.96%'],\n",
       " ['7.91%'],\n",
       " ['5.77%'],\n",
       " ['4.99%'],\n",
       " ['4.57%'],\n",
       " ['4.56%'],\n",
       " ['4.29%'],\n",
       " ['4.14%'],\n",
       " ['4.10%'],\n",
       " ['3.89%'],\n",
       " ['2.81%'],\n",
       " ['2.79%'],\n",
       " ['2.58%'],\n",
       " ['1.67%'],\n",
       " ['1.61%'],\n",
       " ['1.57%'],\n",
       " ['1.30%'],\n",
       " ['0.83%'],\n",
       " ['0.81%'],\n",
       " ['0.39%'],\n",
       " ['0.26%'],\n",
       " ['0.22%'],\n",
       " ['0.18%'],\n",
       " ['0.18%'],\n",
       " ['0.15%'],\n",
       " ['0.15%'],\n",
       " ['0.14%'],\n",
       " ['0.13%'],\n",
       " ['0.12%'],\n",
       " ['-']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_18_19=GSDP_list[1:165:5]\n",
    "share_18_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e588db11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['399.921'],\n",
       " ['247.629'],\n",
       " ['240.726'],\n",
       " ['228.290'],\n",
       " ['226.806'],\n",
       " ['165.556'],\n",
       " ['143.179'],\n",
       " ['131.083'],\n",
       " ['130.791'],\n",
       " ['122.977'],\n",
       " ['118.733'],\n",
       " ['117.703'],\n",
       " ['111.519'],\n",
       " ['80.562'],\n",
       " ['79.957'],\n",
       " ['74.098'],\n",
       " ['47.982'],\n",
       " ['46.187'],\n",
       " ['45.145'],\n",
       " ['37.351'],\n",
       " ['23.690'],\n",
       " ['23.369'],\n",
       " ['11.115'],\n",
       " ['7.571'],\n",
       " ['6.397'],\n",
       " ['5.230'],\n",
       " ['5.086'],\n",
       " ['4.363'],\n",
       " ['4.233'],\n",
       " ['4.144'],\n",
       " ['3.737'],\n",
       " ['3.385'],\n",
       " ['-']]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP_billion=GSDP_list[2:165:5]\n",
    "GDP_billion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f307e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(state),len(GSDP_19_20),len(GSDP_18_19),len(share_18_19),len(GDP_billion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93631533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP(Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[Maharashtra]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[2,632,792]</td>\n",
       "      <td>[13.94%]</td>\n",
       "      <td>[399.921]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[Tamil, Nadu]</td>\n",
       "      <td>[1,845,853]</td>\n",
       "      <td>[1,630,208]</td>\n",
       "      <td>[8.63%]</td>\n",
       "      <td>[247.629]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[Uttar, Pradesh]</td>\n",
       "      <td>[1,687,818]</td>\n",
       "      <td>[1,584,764]</td>\n",
       "      <td>[8.39%]</td>\n",
       "      <td>[240.726]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4]</td>\n",
       "      <td>[Gujarat]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[1,502,899]</td>\n",
       "      <td>[7.96%]</td>\n",
       "      <td>[228.290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[Karnataka]</td>\n",
       "      <td>[1,631,977]</td>\n",
       "      <td>[1,493,127]</td>\n",
       "      <td>[7.91%]</td>\n",
       "      <td>[226.806]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[6]</td>\n",
       "      <td>[West, Bengal]</td>\n",
       "      <td>[1,253,832]</td>\n",
       "      <td>[1,089,898]</td>\n",
       "      <td>[5.77%]</td>\n",
       "      <td>[165.556]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[7]</td>\n",
       "      <td>[Rajasthan]</td>\n",
       "      <td>[1,020,989]</td>\n",
       "      <td>[942,586]</td>\n",
       "      <td>[4.99%]</td>\n",
       "      <td>[143.179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[8]</td>\n",
       "      <td>[Andhra, Pradesh]</td>\n",
       "      <td>[972,782]</td>\n",
       "      <td>[862,957]</td>\n",
       "      <td>[4.57%]</td>\n",
       "      <td>[131.083]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[9]</td>\n",
       "      <td>[Telangana]</td>\n",
       "      <td>[969,604]</td>\n",
       "      <td>[861,031]</td>\n",
       "      <td>[4.56%]</td>\n",
       "      <td>[130.791]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[10]</td>\n",
       "      <td>[Madhya, Pradesh]</td>\n",
       "      <td>[906,672]</td>\n",
       "      <td>[809,592]</td>\n",
       "      <td>[4.29%]</td>\n",
       "      <td>[122.977]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[11]</td>\n",
       "      <td>[Kerala]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[781,653]</td>\n",
       "      <td>[4.14%]</td>\n",
       "      <td>[118.733]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[12]</td>\n",
       "      <td>[Delhi]</td>\n",
       "      <td>[856,112]</td>\n",
       "      <td>[774,870]</td>\n",
       "      <td>[4.10%]</td>\n",
       "      <td>[117.703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[13]</td>\n",
       "      <td>[Haryana]</td>\n",
       "      <td>[831,610]</td>\n",
       "      <td>[734,163]</td>\n",
       "      <td>[3.89%]</td>\n",
       "      <td>[111.519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[14]</td>\n",
       "      <td>[Bihar]</td>\n",
       "      <td>[611,804]</td>\n",
       "      <td>[530,363]</td>\n",
       "      <td>[2.81%]</td>\n",
       "      <td>[80.562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[15]</td>\n",
       "      <td>[Punjab]</td>\n",
       "      <td>[574,760]</td>\n",
       "      <td>[526,376]</td>\n",
       "      <td>[2.79%]</td>\n",
       "      <td>[79.957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[16]</td>\n",
       "      <td>[Odisha]</td>\n",
       "      <td>[521,275]</td>\n",
       "      <td>[487,805]</td>\n",
       "      <td>[2.58%]</td>\n",
       "      <td>[74.098]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[17]</td>\n",
       "      <td>[Assam]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[315,881]</td>\n",
       "      <td>[1.67%]</td>\n",
       "      <td>[47.982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[18]</td>\n",
       "      <td>[Chhattisgarh]</td>\n",
       "      <td>[329,180]</td>\n",
       "      <td>[304,063]</td>\n",
       "      <td>[1.61%]</td>\n",
       "      <td>[46.187]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[19]</td>\n",
       "      <td>[Jharkhand]</td>\n",
       "      <td>[328,598]</td>\n",
       "      <td>[297,204]</td>\n",
       "      <td>[1.57%]</td>\n",
       "      <td>[45.145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[20]</td>\n",
       "      <td>[Uttarakhand]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[245,895]</td>\n",
       "      <td>[1.30%]</td>\n",
       "      <td>[37.351]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[21]</td>\n",
       "      <td>[Jammu, &amp;, Kashmir]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[155,956]</td>\n",
       "      <td>[0.83%]</td>\n",
       "      <td>[23.690]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[22]</td>\n",
       "      <td>[Himachal, Pradesh]</td>\n",
       "      <td>[165,472]</td>\n",
       "      <td>[153,845]</td>\n",
       "      <td>[0.81%]</td>\n",
       "      <td>[23.369]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[23]</td>\n",
       "      <td>[Goa]</td>\n",
       "      <td>[80,449]</td>\n",
       "      <td>[73,170]</td>\n",
       "      <td>[0.39%]</td>\n",
       "      <td>[11.115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[24]</td>\n",
       "      <td>[Tripura]</td>\n",
       "      <td>[55,984]</td>\n",
       "      <td>[49,845]</td>\n",
       "      <td>[0.26%]</td>\n",
       "      <td>[7.571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[25]</td>\n",
       "      <td>[Chandigarh]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[42,114]</td>\n",
       "      <td>[0.22%]</td>\n",
       "      <td>[6.397]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[26]</td>\n",
       "      <td>[Puducherry]</td>\n",
       "      <td>[38,253]</td>\n",
       "      <td>[34,433]</td>\n",
       "      <td>[0.18%]</td>\n",
       "      <td>[5.230]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[27]</td>\n",
       "      <td>[Meghalaya]</td>\n",
       "      <td>[36,572]</td>\n",
       "      <td>[33,481]</td>\n",
       "      <td>[0.18%]</td>\n",
       "      <td>[5.086]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[28]</td>\n",
       "      <td>[Sikkim]</td>\n",
       "      <td>[32,496]</td>\n",
       "      <td>[28,723]</td>\n",
       "      <td>[0.15%]</td>\n",
       "      <td>[4.363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[29]</td>\n",
       "      <td>[Manipur]</td>\n",
       "      <td>[31,790]</td>\n",
       "      <td>[27,870]</td>\n",
       "      <td>[0.15%]</td>\n",
       "      <td>[4.233]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[30]</td>\n",
       "      <td>[Nagaland]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[27,283]</td>\n",
       "      <td>[0.14%]</td>\n",
       "      <td>[4.144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[31]</td>\n",
       "      <td>[Arunachal, Pradesh]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[24,603]</td>\n",
       "      <td>[0.13%]</td>\n",
       "      <td>[3.737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[32]</td>\n",
       "      <td>[Mizoram]</td>\n",
       "      <td>[26,503]</td>\n",
       "      <td>[22,287]</td>\n",
       "      <td>[0.12%]</td>\n",
       "      <td>[3.385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[33]</td>\n",
       "      <td>[Andaman, &amp;, Nicobar, Islands]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[-]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                           State  GSDP(19-20)  GSDP(18-19)  \\\n",
       "0    [1]                   [Maharashtra]          [-]  [2,632,792]   \n",
       "1    [2]                   [Tamil, Nadu]  [1,845,853]  [1,630,208]   \n",
       "2    [3]                [Uttar, Pradesh]  [1,687,818]  [1,584,764]   \n",
       "3    [4]                       [Gujarat]          [-]  [1,502,899]   \n",
       "4    [5]                     [Karnataka]  [1,631,977]  [1,493,127]   \n",
       "5    [6]                  [West, Bengal]  [1,253,832]  [1,089,898]   \n",
       "6    [7]                     [Rajasthan]  [1,020,989]    [942,586]   \n",
       "7    [8]               [Andhra, Pradesh]    [972,782]    [862,957]   \n",
       "8    [9]                     [Telangana]    [969,604]    [861,031]   \n",
       "9   [10]               [Madhya, Pradesh]    [906,672]    [809,592]   \n",
       "10  [11]                        [Kerala]          [-]    [781,653]   \n",
       "11  [12]                         [Delhi]    [856,112]    [774,870]   \n",
       "12  [13]                       [Haryana]    [831,610]    [734,163]   \n",
       "13  [14]                         [Bihar]    [611,804]    [530,363]   \n",
       "14  [15]                        [Punjab]    [574,760]    [526,376]   \n",
       "15  [16]                        [Odisha]    [521,275]    [487,805]   \n",
       "16  [17]                         [Assam]          [-]    [315,881]   \n",
       "17  [18]                  [Chhattisgarh]    [329,180]    [304,063]   \n",
       "18  [19]                     [Jharkhand]    [328,598]    [297,204]   \n",
       "19  [20]                   [Uttarakhand]          [-]    [245,895]   \n",
       "20  [21]             [Jammu, &, Kashmir]          [-]    [155,956]   \n",
       "21  [22]             [Himachal, Pradesh]    [165,472]    [153,845]   \n",
       "22  [23]                           [Goa]     [80,449]     [73,170]   \n",
       "23  [24]                       [Tripura]     [55,984]     [49,845]   \n",
       "24  [25]                    [Chandigarh]          [-]     [42,114]   \n",
       "25  [26]                    [Puducherry]     [38,253]     [34,433]   \n",
       "26  [27]                     [Meghalaya]     [36,572]     [33,481]   \n",
       "27  [28]                        [Sikkim]     [32,496]     [28,723]   \n",
       "28  [29]                       [Manipur]     [31,790]     [27,870]   \n",
       "29  [30]                      [Nagaland]          [-]     [27,283]   \n",
       "30  [31]            [Arunachal, Pradesh]          [-]     [24,603]   \n",
       "31  [32]                       [Mizoram]     [26,503]     [22,287]   \n",
       "32  [33]  [Andaman, &, Nicobar, Islands]          [-]          [-]   \n",
       "\n",
       "   Share(18-19) GDP(Billion)  \n",
       "0      [13.94%]    [399.921]  \n",
       "1       [8.63%]    [247.629]  \n",
       "2       [8.39%]    [240.726]  \n",
       "3       [7.96%]    [228.290]  \n",
       "4       [7.91%]    [226.806]  \n",
       "5       [5.77%]    [165.556]  \n",
       "6       [4.99%]    [143.179]  \n",
       "7       [4.57%]    [131.083]  \n",
       "8       [4.56%]    [130.791]  \n",
       "9       [4.29%]    [122.977]  \n",
       "10      [4.14%]    [118.733]  \n",
       "11      [4.10%]    [117.703]  \n",
       "12      [3.89%]    [111.519]  \n",
       "13      [2.81%]     [80.562]  \n",
       "14      [2.79%]     [79.957]  \n",
       "15      [2.58%]     [74.098]  \n",
       "16      [1.67%]     [47.982]  \n",
       "17      [1.61%]     [46.187]  \n",
       "18      [1.57%]     [45.145]  \n",
       "19      [1.30%]     [37.351]  \n",
       "20      [0.83%]     [23.690]  \n",
       "21      [0.81%]     [23.369]  \n",
       "22      [0.39%]     [11.115]  \n",
       "23      [0.26%]      [7.571]  \n",
       "24      [0.22%]      [6.397]  \n",
       "25      [0.18%]      [5.230]  \n",
       "26      [0.18%]      [5.086]  \n",
       "27      [0.15%]      [4.363]  \n",
       "28      [0.15%]      [4.233]  \n",
       "29      [0.14%]      [4.144]  \n",
       "30      [0.13%]      [3.737]  \n",
       "31      [0.12%]      [3.385]  \n",
       "32          [-]          [-]  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':rank,'State':state,'GSDP(19-20)':GSDP_19_20,'GSDP(18-19)':GSDP_18_19,'Share(18-19)':share_18_19,'GDP(Billion)':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b521b6e7",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc718efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32a879b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eea9e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]')\n",
    "c1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d2d55818",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "c2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "18c0894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_title=[]\n",
    "rt=driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "for i in rt[0:25]:\n",
    "    rt1=i.text.split()[0]\n",
    "    repository_title.append(rt1)\n",
    "    \n",
    "repository_des=[]\n",
    "rd=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in rd[0:25]:\n",
    "    rd1=i.text\n",
    "    repository_des.append(rd1)\n",
    "    \n",
    "language_used=[]\n",
    "lu=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in lu[0:25]:\n",
    "    lu1=i.text\n",
    "    language_used.append(lu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d905c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_data=[]\n",
    "md=driver.find_elements(By.XPATH,'//a[@class=\"Link--muted d-inline-block mr-3\"]')\n",
    "for i in md[0:50]:\n",
    "    md1=i.text.split()\n",
    "    multiple_data.append(md1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6d64e504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2,137'],\n",
       " ['182'],\n",
       " ['3,219'],\n",
       " ['338'],\n",
       " ['1,264'],\n",
       " ['363'],\n",
       " ['10,673'],\n",
       " ['463'],\n",
       " ['4,496'],\n",
       " ['95'],\n",
       " ['31,624'],\n",
       " ['2,511'],\n",
       " ['15,485'],\n",
       " ['1,983'],\n",
       " ['143,206'],\n",
       " ['36,626'],\n",
       " ['62,330'],\n",
       " ['5,909'],\n",
       " ['440'],\n",
       " ['87'],\n",
       " ['2,015'],\n",
       " ['40'],\n",
       " ['1,201'],\n",
       " ['135'],\n",
       " ['596'],\n",
       " ['15'],\n",
       " ['579'],\n",
       " ['33'],\n",
       " ['8,452'],\n",
       " ['1,953'],\n",
       " ['11,839'],\n",
       " ['785'],\n",
       " ['6,224'],\n",
       " ['11,594'],\n",
       " ['14,235'],\n",
       " ['873'],\n",
       " ['141,082'],\n",
       " ['21,839'],\n",
       " ['77,849'],\n",
       " ['4,434'],\n",
       " ['2,265'],\n",
       " ['555'],\n",
       " ['86'],\n",
       " ['7'],\n",
       " ['39,113'],\n",
       " ['2,856'],\n",
       " ['17,549'],\n",
       " ['1,318'],\n",
       " ['12,561'],\n",
       " ['7,707']]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e5fd3675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['182'],\n",
       " ['338'],\n",
       " ['363'],\n",
       " ['463'],\n",
       " ['95'],\n",
       " ['2,511'],\n",
       " ['1,983'],\n",
       " ['36,626'],\n",
       " ['5,909'],\n",
       " ['87'],\n",
       " ['40'],\n",
       " ['135'],\n",
       " ['15'],\n",
       " ['33'],\n",
       " ['1,953'],\n",
       " ['785'],\n",
       " ['11,594'],\n",
       " ['873'],\n",
       " ['21,839'],\n",
       " ['4,434'],\n",
       " ['555'],\n",
       " ['7'],\n",
       " ['2,856'],\n",
       " ['1,318'],\n",
       " ['7,707']]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributors_count=multiple_data[1:50:2]\n",
    "contributors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1928fe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'Python',\n",
       " 'Shell',\n",
       " 'TypeScript',\n",
       " 'Rust',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Python',\n",
       " 'Rust',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'Jupyter Notebook',\n",
       " 'JavaScript',\n",
       " 'Jupyter Notebook',\n",
       " 'Lua',\n",
       " 'Markdown',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'C#',\n",
       " 'Java',\n",
       " 'C',\n",
       " 'Zig',\n",
       " 'C']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e97f156d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(language_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c402a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_used.insert(-3,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "480e0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_used.insert(8,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7998c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'Python',\n",
       " 'Shell',\n",
       " 'TypeScript',\n",
       " 'Rust',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Python',\n",
       " '-',\n",
       " 'Rust',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'Jupyter Notebook',\n",
       " 'JavaScript',\n",
       " 'Jupyter Notebook',\n",
       " 'Lua',\n",
       " 'Markdown',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'C#',\n",
       " 'Java',\n",
       " '-',\n",
       " 'C',\n",
       " 'Zig',\n",
       " 'C']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b7d8b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repository_title),len(repository_des),len(contributors_count),len(language_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "787bab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOMATIC1111</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>[182]</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sd-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>[338]</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>somebasj</td>\n",
       "      <td>Parallels Desktop for mac Crack</td>\n",
       "      <td>[363]</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AykutSarac</td>\n",
       "      <td>🔮 Seamlessly visualize your JSON data instantl...</td>\n",
       "      <td>[463]</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surrealdb</td>\n",
       "      <td>A scalable, distributed, collaborative, docume...</td>\n",
       "      <td>[95]</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yt-dlp</td>\n",
       "      <td>A youtube-dl fork with additional features and...</td>\n",
       "      <td>[2,511]</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>termux</td>\n",
       "      <td>Termux - a terminal emulator application for A...</td>\n",
       "      <td>[1,983]</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheAlgorithms</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>[36,626]</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mtdvio</td>\n",
       "      <td>A collection of (mostly) technical things ever...</td>\n",
       "      <td>[5,909]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alcibiades-Capital</td>\n",
       "      <td>A MEV bundle generator written in Rust</td>\n",
       "      <td>[87]</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meienberger</td>\n",
       "      <td>⛺️ Tipi is a homeserver for everyone! One comm...</td>\n",
       "      <td>[40]</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hiroi-sora</td>\n",
       "      <td>OCR批量图片转文字识别软件，带界面，离线运行。可排除图片中水印区域的干扰，提取干净的文本。...</td>\n",
       "      <td>[135]</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>karpathy</td>\n",
       "      <td>Neural Networks: Zero to Hero</td>\n",
       "      <td>[15]</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>benphelps</td>\n",
       "      <td>A highly customizable homepage (or startpage /...</td>\n",
       "      <td>[33]</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jaakkopasanen</td>\n",
       "      <td>Automatic headphone equalization from frequenc...</td>\n",
       "      <td>[1,953]</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NvChad</td>\n",
       "      <td>An attempt to make neovim cli functional like ...</td>\n",
       "      <td>[785]</td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mdn</td>\n",
       "      <td>The content behind MDN Web Docs</td>\n",
       "      <td>[11,594]</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mantinedev</td>\n",
       "      <td>React components library with native dark them...</td>\n",
       "      <td>[873]</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vinta</td>\n",
       "      <td>A curated list of awesome Python frameworks, l...</td>\n",
       "      <td>[21,839]</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>[4,434]</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>apache</td>\n",
       "      <td>StreamPark, Make stream processing easier! eas...</td>\n",
       "      <td>[555]</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34306</td>\n",
       "      <td>This repo saved iPA for TrollStore, work as ja...</td>\n",
       "      <td>[7]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ventoy</td>\n",
       "      <td>A new bootable USB solution.</td>\n",
       "      <td>[2,856]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ziglang</td>\n",
       "      <td>General-purpose programming language and toolc...</td>\n",
       "      <td>[1,318]</td>\n",
       "      <td>Zig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>openwrt</td>\n",
       "      <td>This repository is a mirror of https://git.ope...</td>\n",
       "      <td>[7,707]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Repository Title                             Repository Description  \\\n",
       "0        AUTOMATIC1111                            Stable Diffusion web UI   \n",
       "1             sd-webui                            Stable Diffusion web UI   \n",
       "2             somebasj                    Parallels Desktop for mac Crack   \n",
       "3           AykutSarac  🔮 Seamlessly visualize your JSON data instantl...   \n",
       "4            surrealdb  A scalable, distributed, collaborative, docume...   \n",
       "5               yt-dlp  A youtube-dl fork with additional features and...   \n",
       "6               termux  Termux - a terminal emulator application for A...   \n",
       "7        TheAlgorithms               All Algorithms implemented in Python   \n",
       "8               mtdvio  A collection of (mostly) technical things ever...   \n",
       "9   Alcibiades-Capital             A MEV bundle generator written in Rust   \n",
       "10         meienberger  ⛺️ Tipi is a homeserver for everyone! One comm...   \n",
       "11          hiroi-sora  OCR批量图片转文字识别软件，带界面，离线运行。可排除图片中水印区域的干扰，提取干净的文本。...   \n",
       "12            karpathy                      Neural Networks: Zero to Hero   \n",
       "13           benphelps  A highly customizable homepage (or startpage /...   \n",
       "14       jaakkopasanen  Automatic headphone equalization from frequenc...   \n",
       "15              NvChad  An attempt to make neovim cli functional like ...   \n",
       "16                 mdn                    The content behind MDN Web Docs   \n",
       "17          mantinedev  React components library with native dark them...   \n",
       "18               vinta  A curated list of awesome Python frameworks, l...   \n",
       "19           microsoft  Windows system utilities to maximize productivity   \n",
       "20              apache  StreamPark, Make stream processing easier! eas...   \n",
       "21               34306  This repo saved iPA for TrollStore, work as ja...   \n",
       "22              ventoy                       A new bootable USB solution.   \n",
       "23             ziglang  General-purpose programming language and toolc...   \n",
       "24             openwrt  This repository is a mirror of https://git.ope...   \n",
       "\n",
       "   Contributors Count     Language Used  \n",
       "0               [182]            Python  \n",
       "1               [338]            Python  \n",
       "2               [363]             Shell  \n",
       "3               [463]        TypeScript  \n",
       "4                [95]              Rust  \n",
       "5             [2,511]            Python  \n",
       "6             [1,983]              Java  \n",
       "7            [36,626]            Python  \n",
       "8             [5,909]                 -  \n",
       "9                [87]              Rust  \n",
       "10               [40]        TypeScript  \n",
       "11              [135]            Python  \n",
       "12               [15]  Jupyter Notebook  \n",
       "13               [33]        JavaScript  \n",
       "14            [1,953]  Jupyter Notebook  \n",
       "15              [785]               Lua  \n",
       "16           [11,594]          Markdown  \n",
       "17              [873]        TypeScript  \n",
       "18           [21,839]            Python  \n",
       "19            [4,434]                C#  \n",
       "20              [555]              Java  \n",
       "21                [7]                 -  \n",
       "22            [2,856]                 C  \n",
       "23            [1,318]               Zig  \n",
       "24            [7,707]                 C  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Repository Title':repository_title,'Repository Description':repository_des,'Contributors Count':contributors_count,'Language Used':language_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63879d6b",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1c0b65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "549878f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https:/www.billboard.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "150828e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'/html/body/div[3]/header/div[1]/div/div/div[2]/div/nav/ul/li[1]')\n",
    "c1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "10e1179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2=driver.find_element(By.XPATH,'/html/body/div[3]/header/div[2]/div/nav/ul/li[1]')\n",
    "c2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "01f2e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week=[]\n",
    "pos_list=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "for i in pos_list[0:100]:\n",
    "    lw1=i.text.split()[-3]\n",
    "    last_week.append(lw1)\n",
    "    \n",
    "peak_rank=[]\n",
    "pos_list=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "for i in pos_list[0:100]:\n",
    "    pr1=i.text.split()[-2]\n",
    "    peak_rank.append(pr1)\n",
    "    \n",
    "week_board=[]\n",
    "pos_list=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "for i in pos_list[0:100]:\n",
    "    wb1=i.text.split()[-1]\n",
    "    week_board.append(wb1)\n",
    "    \n",
    "song_name=[]\n",
    "sn=driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in sn[0:99]:\n",
    "    sn1=i.text\n",
    "    song_name.append(sn1)\n",
    "    \n",
    "artist_name=[]\n",
    "an=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in an[0:99]:\n",
    "    an1=i.text\n",
    "    artist_name.append(an1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "53d1e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_song=[]\n",
    "fs=driver.find_element(By.XPATH,'//li[@class=\"o-chart-results-list__item // lrv-u-flex-grow-1 lrv-u-flex lrv-u-flex-direction-column lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light  lrv-u-padding-l-1@mobile-max\"]')\n",
    "first_song.append(fs.text.replace('\\n',\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1ff98039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As It Was Harry Styles']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4581a5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As It Was']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_song_name=[first_song[0][:9]]\n",
    "first_song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "884aafad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Styles']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_artist_name=[first_song[0][10:]]\n",
    "first_artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6272a1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As It Was',\n",
       " 'Bad Habit',\n",
       " 'About Damn Time',\n",
       " 'Running Up That Hill (A Deal With God)',\n",
       " 'Sunroof',\n",
       " 'Hold Me Closer',\n",
       " 'Super Freaky Girl',\n",
       " 'I Like You (A Happier Song)',\n",
       " 'Break My Soul',\n",
       " 'Wait For U',\n",
       " 'Me Porto Bonito',\n",
       " 'Late Night Talking',\n",
       " 'You Proof',\n",
       " \"I Ain't Worried\",\n",
       " 'The Kind Of Love We Make',\n",
       " 'Titi Me Pregunto',\n",
       " 'God Did',\n",
       " 'First Class',\n",
       " 'Heat Waves',\n",
       " 'Wasted On You',\n",
       " 'Staying Alive',\n",
       " 'She Had Me At Heads Carolina',\n",
       " 'Jimmy Cooks',\n",
       " 'Stay',\n",
       " 'Vegas',\n",
       " 'Glimpse Of Us',\n",
       " 'Last Night Lonely',\n",
       " '5 Foot 9',\n",
       " 'Beautiful',\n",
       " 'Moscow Mule',\n",
       " 'Big Time',\n",
       " 'Big Energy',\n",
       " 'Betty (Get Money)',\n",
       " 'Ghost',\n",
       " 'Shivers',\n",
       " 'Beat The Odds',\n",
       " 'Gatubela',\n",
       " 'Rock And A Hard Place',\n",
       " 'Efecto',\n",
       " 'In A Minute',\n",
       " 'Cold Heart (PNAU Remix)',\n",
       " 'Something In The Orange',\n",
       " 'Son Of A Sinner',\n",
       " 'Numb',\n",
       " 'Fall In Love',\n",
       " 'Provenza',\n",
       " 'Left And Right',\n",
       " 'Numb Little Bug',\n",
       " 'Use This Gospel (Remix)',\n",
       " 'Unstoppable',\n",
       " 'Wishful Drinking',\n",
       " 'Like I Love Country Music',\n",
       " 'Pink Venom',\n",
       " 'Dah Dah DahDah',\n",
       " 'Juice WRLD Did',\n",
       " 'Sticky',\n",
       " 'Keep Going',\n",
       " 'Bones',\n",
       " 'Victoria’s Secret',\n",
       " 'Hot Shit',\n",
       " 'Free Mind',\n",
       " 'Sleazy Flow',\n",
       " 'So Good',\n",
       " 'With A Woman You Love',\n",
       " 'Party',\n",
       " 'Party',\n",
       " 'Last Last',\n",
       " 'Ojitos Lindos',\n",
       " 'Die For You',\n",
       " 'Truth About You',\n",
       " 'Golden Hour',\n",
       " 'Where It Ends',\n",
       " \"F.N.F. (Let's Go)\",\n",
       " 'Despues de La Playa',\n",
       " 'Despecha',\n",
       " 'Alone',\n",
       " \"It Ain't Safe\",\n",
       " 'No Secret',\n",
       " 'Neverita',\n",
       " 'Pick Me Up',\n",
       " \"I'm Good (Blue)\",\n",
       " 'Whiskey On You',\n",
       " 'Tarot',\n",
       " 'She Likes It',\n",
       " 'Ghost Story',\n",
       " \"Let's Pray\",\n",
       " 'Until I Found You',\n",
       " 'All Mine',\n",
       " 'Bad Decisions',\n",
       " 'Alien Superstar',\n",
       " 'Puffin On Zootiez',\n",
       " 'Half Of Me',\n",
       " 'What My World Spins Around',\n",
       " 'Hotel Lobby (Unc And Phew)',\n",
       " 'La Bachata',\n",
       " 'Thought You Should Know',\n",
       " '2 Be Loved (Am I Ready)',\n",
       " 'Wait In The Truck',\n",
       " 'La Corriente',\n",
       " 'Bzrp Music Sessions, Vol. 52']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_song_name=first_song_name+song_name\n",
    "new_song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c39aafd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Styles',\n",
       " 'Steve Lacy',\n",
       " 'Lizzo',\n",
       " 'Kate Bush',\n",
       " 'Nicky Youre & dazy',\n",
       " 'Elton John & Britney Spears',\n",
       " 'Nicki Minaj',\n",
       " 'Post Malone Featuring Doja Cat',\n",
       " 'Beyonce',\n",
       " 'Future Featuring Drake & Tems',\n",
       " 'Bad Bunny & Chencho Corleone',\n",
       " 'Harry Styles',\n",
       " 'Morgan Wallen',\n",
       " 'OneRepublic',\n",
       " 'Luke Combs',\n",
       " 'Bad Bunny',\n",
       " 'DJ Khaled Featuring Rick Ross, Lil Wayne, JAY-Z, John Legend & Fridayy',\n",
       " 'Jack Harlow',\n",
       " 'Glass Animals',\n",
       " 'Morgan Wallen',\n",
       " 'DJ Khaled Featuring Drake & Lil Baby',\n",
       " 'Cole Swindell',\n",
       " 'Drake Featuring 21 Savage',\n",
       " 'The Kid LAROI & Justin Bieber',\n",
       " 'Doja Cat',\n",
       " 'Joji',\n",
       " 'Jon Pardi',\n",
       " 'Tyler Hubbard',\n",
       " 'DJ Khaled Featuring Future & SZA',\n",
       " 'Bad Bunny',\n",
       " 'DJ Khaled Featuring Future & Lil Baby',\n",
       " 'Latto',\n",
       " 'Yung Gravy',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Lil Tjay',\n",
       " 'Karol G x Maldy',\n",
       " 'Bailey Zimmerman',\n",
       " 'Bad Bunny',\n",
       " 'Lil Baby',\n",
       " 'Elton John & Dua Lipa',\n",
       " 'Zach Bryan',\n",
       " 'Jelly Roll',\n",
       " 'Marshmello & Khalid',\n",
       " 'Bailey Zimmerman',\n",
       " 'Karol G',\n",
       " 'Charlie Puth Featuring Jung Kook',\n",
       " 'Em Beihold',\n",
       " 'DJ Khaled Featuring Kanye West & Eminem',\n",
       " 'Sia',\n",
       " 'Ingrid Andress With Sam Hunt',\n",
       " 'Kane Brown',\n",
       " 'BLACKPINK',\n",
       " 'Nardo Wick',\n",
       " 'DJ Khaled Featuring Juice WRLD',\n",
       " 'Drake',\n",
       " 'DJ Khaled Featuring Lil Durk, 21 Savage & Roddy Ricch',\n",
       " 'Imagine Dragons',\n",
       " 'Jax',\n",
       " 'Cardi B, Ye & Lil Durk',\n",
       " 'Tems',\n",
       " 'SleazyWorld Go Featuring Lil Baby',\n",
       " 'Halsey',\n",
       " 'Justin Moore',\n",
       " 'Bad Bunny & Rauw Alejandro',\n",
       " 'DJ Khaled Featuring Quavo & Takeoff',\n",
       " 'Burna Boy',\n",
       " 'Bad Bunny & Bomba Estereo',\n",
       " 'The Weeknd',\n",
       " 'Mitchell Tenpenny',\n",
       " 'JVKE',\n",
       " 'Bailey Zimmerman',\n",
       " 'Hitkidd & GloRilla',\n",
       " 'Bad Bunny',\n",
       " 'Rosalia',\n",
       " 'Rod Wave',\n",
       " 'DJ Khaled Featuring Nardo Wick & Kodak Black',\n",
       " 'DJ Khaled Featuring Drake',\n",
       " 'Bad Bunny',\n",
       " 'Gabby Barrett',\n",
       " 'David Guetta & Bebe Rexha',\n",
       " 'Nate Smith',\n",
       " 'Bad Bunny & Jhay Cortez',\n",
       " 'Russell Dickerson & Jake Scott',\n",
       " 'Carrie Underwood',\n",
       " 'DJ Khaled Featuring Don Toliver & Travis Scott',\n",
       " 'Stephen Sanchez',\n",
       " 'Brent Faiyaz',\n",
       " 'benny blanco, BTS & Snoop Dogg',\n",
       " 'Beyonce',\n",
       " 'Future',\n",
       " 'Thomas Rhett Featuring Riley Green',\n",
       " 'Jordan Davis',\n",
       " 'Quavo & Takeoff',\n",
       " 'Manuel Turizo',\n",
       " 'Morgan Wallen',\n",
       " 'Lizzo',\n",
       " 'HARDY Featuring Lainey Wilson',\n",
       " 'Bad Bunny & Tony Dize',\n",
       " 'Bizarrap & Quevedo']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_artist_name=first_artist_name+artist_name\n",
    "new_artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "774f9ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(new_song_name),len(new_artist_name),len(last_week),len(peak_rank),len(week_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c99627f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Habit</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About Damn Time</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Running Up That Hill (A Deal With God)</td>\n",
       "      <td>Kate Bush</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunroof</td>\n",
       "      <td>Nicky Youre &amp; dazy</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Thought You Should Know</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2 Be Loved (Am I Ready)</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wait In The Truck</td>\n",
       "      <td>HARDY Featuring Lainey Wilson</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>La Corriente</td>\n",
       "      <td>Bad Bunny &amp; Tony Dize</td>\n",
       "      <td>87</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 52</td>\n",
       "      <td>Bizarrap &amp; Quevedo</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Song Name                    Artist Name  \\\n",
       "0                                As It Was                   Harry Styles   \n",
       "1                                Bad Habit                     Steve Lacy   \n",
       "2                          About Damn Time                          Lizzo   \n",
       "3   Running Up That Hill (A Deal With God)                      Kate Bush   \n",
       "4                                  Sunroof             Nicky Youre & dazy   \n",
       "..                                     ...                            ...   \n",
       "95                 Thought You Should Know                  Morgan Wallen   \n",
       "96                 2 Be Loved (Am I Ready)                          Lizzo   \n",
       "97                       Wait In The Truck  HARDY Featuring Lainey Wilson   \n",
       "98                            La Corriente          Bad Bunny & Tony Dize   \n",
       "99            Bzrp Music Sessions, Vol. 52             Bizarrap & Quevedo   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Board  \n",
       "0               1         1             22  \n",
       "1               3         2              9  \n",
       "2               2         1             20  \n",
       "3               4         3             34  \n",
       "4               6         5             14  \n",
       "..            ...       ...            ...  \n",
       "95             81        12             17  \n",
       "96             95        84              3  \n",
       "97              -        98              1  \n",
       "98             87        32             14  \n",
       "99             82        82              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Song Name':new_song_name,'Artist Name':new_artist_name,'Last Week Rank':last_week,'Peak Rank':peak_rank,'Weeks on Board':week_board})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2715c2c6",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/ - \"https://www.naukri.com/hr-recruiters-consultants\"\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c92d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a77be52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can't find recruiter option on page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd5a06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "d.send_keys('Data Science')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6be8555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[2]/ul/li[1]')\n",
    "c1.click()\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e75b9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "n1=driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "for i in n1[0:50]:\n",
    "    n11=i.text\n",
    "    name.append(n11)\n",
    "    \n",
    "designation=[]\n",
    "d1=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "for i in d1[0:50]:\n",
    "    d11=i.text\n",
    "    designation.append(d11)\n",
    "    \n",
    "skills=[]\n",
    "s1=driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "for i in s1[0:50]:\n",
    "    s11=i.text\n",
    "    skills.append(s11)\n",
    "\n",
    "location=[]\n",
    "l1=driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]')\n",
    "for i in l1[0:50]:\n",
    "    l11=i.text\n",
    "    location.append(l11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4e84eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'UK - (london)',\n",
       " 'Vadodara / Baroda',\n",
       " 'Chennai',\n",
       " 'Trivandrum',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bhopal',\n",
       " 'Chandigarh',\n",
       " 'Pune',\n",
       " 'Navi Mumbai',\n",
       " 'Cochin',\n",
       " 'Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mysoru / Mysore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'New Delhi',\n",
       " 'Chennai',\n",
       " 'Aligarh',\n",
       " 'Salt Lake City',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'MYSORE',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "443d2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location.insert(29,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be4d137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location.insert(48,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09c4f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(designation),len(skills),len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca334cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                 Priyanka Akiri   \n",
       "11                                Kalpana Dumpala   \n",
       "12                                        Mubarak   \n",
       "13                                 Kushal Rastogi   \n",
       "14                             Vaishnavi Kudalkar   \n",
       "15                             Mahesh Babu Channa   \n",
       "16                                   Kapil Devang   \n",
       "17                                Sakshi Chhikara   \n",
       "18                                    Ruchi Dhote   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                             Sandhya Khandagale   \n",
       "25                                      Shaun Rao   \n",
       "26                                  Azahar Shaikh   \n",
       "27                                          Manas   \n",
       "28                                          kumar   \n",
       "29                                   Sunil Vedula   \n",
       "30                                    Rajat Kumar   \n",
       "31                                Dhruv Dev Dubey   \n",
       "32                                      Jayanth N   \n",
       "33                                         Avodha   \n",
       "34                                    Priya Khare   \n",
       "35                                    Amit Sharma   \n",
       "36                                          Kanan   \n",
       "37                           Shashikant Chaudhary   \n",
       "38                                           Brad   \n",
       "39                                   Rutuja Pawar   \n",
       "40                            Madhusudhan Sridhar   \n",
       "41                                    Ankit Sinha   \n",
       "42                                 Gaurav Chouhan   \n",
       "43                                   Rashi Kacker   \n",
       "44                                        Ashwini   \n",
       "45                                   Balaji Kolli   \n",
       "46                                 Rajani Nagaraj   \n",
       "47                                    ROHIT Kumar   \n",
       "48                                 Amir Chowdhury   \n",
       "49                                       SREEDHAR   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                           HR Manager   \n",
       "11                     Executive Hiring   \n",
       "12                           Company HR   \n",
       "13                           Company HR   \n",
       "14                         HR Executive   \n",
       "15                         HR Team Lead   \n",
       "16                           HR Manager   \n",
       "17                 Assistant Manager HR   \n",
       "18  Senior Executive Talent Acquisition   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24                         HR Recruiter   \n",
       "25              Manager Human Resources   \n",
       "26                    Company Recruiter   \n",
       "27              Lead Talent acquisition   \n",
       "28                           Proprietor   \n",
       "29                                  CEO   \n",
       "30                          Founder CEO   \n",
       "31             Company Recruitment Head   \n",
       "32                      Project Manager   \n",
       "33       Business Development Associate   \n",
       "34                       Senior Manager   \n",
       "35                           Consultant   \n",
       "36         senior technology instructor   \n",
       "37             HR Recruiter/HR Excutive   \n",
       "38        Manager, Technical Recruiting   \n",
       "39                  Technical Recruiter   \n",
       "40                      Erp Implementer   \n",
       "41                       Head Analytics   \n",
       "42              Chief Technical Officer   \n",
       "43                   Sr Product Manager   \n",
       "44             Director Global Delivery   \n",
       "45                           Co Founder   \n",
       "46                           HR Manager   \n",
       "47                            Architect   \n",
       "48                     Managing Partner   \n",
       "49               Recruitment Consultant   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   Classic ASP Developer, Internet Marketing Prof...   \n",
       "1   .Net, Java, Data Science, Linux Administration...   \n",
       "2   Data Science, Artificial Intelligence, Machine...   \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "5   Analytics, Business Intelligence, Business Ana...   \n",
       "6                                        Data Science   \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...   \n",
       "8   Technical Training, Software Development, Pres...   \n",
       "9   Software Development, It Sales, Account Manage...   \n",
       "10  Oracle Dba, Data Science, Data Warehousing, ET...   \n",
       "11  Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
       "12  Business Intelligence, Data Warehousing, Data ...   \n",
       "13  Office Administration, Hr Administration, tele...   \n",
       "14               Data Science, Python, Data Analytics   \n",
       "15  Social Media, digital media maketing, seo, smm...   \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science   \n",
       "17  React.js, Data Science, Java, Front End, Busin...   \n",
       "18  Qlikview, Qlik Sense, Microsoft Azure, Power B...   \n",
       "19  Telecalling, Client Interaction, Marketing, Re...   \n",
       "20                                       Data Science   \n",
       "21  Corporate Sales, Software Development, Softwar...   \n",
       "22  Data Analytics, Data Science, Machine Learning...   \n",
       "23  Data Science, Machine Learning, Python, R, Dee...   \n",
       "24  Big Data, Data Science, Artificial Intelligenc...   \n",
       "25  Java, Net, Angularjs, Hr, Infrastructure, Mana...   \n",
       "26  Data Science, Artificial Intelligence, Machine...   \n",
       "27  Software Architecture, Vp Engineering, Product...   \n",
       "28  Data Science, Hadoop, Rpas, Devops, Python, Aw...   \n",
       "29  Signal Processing, Machine Learning, Neural Ne...   \n",
       "30  Web Technologies, Project Management, Software...   \n",
       "31  Server Administartion, Verilog, Vhdl, Digital ...   \n",
       "32  Data Analytics, Managed Services, Team Leading...   \n",
       "33  Ethical Hacking, Security Operations Center, S...   \n",
       "34  Data Science, Artificial Intelligence, analyti...   \n",
       "35  Machine Learning, Artificial Intelligence, Dat...   \n",
       "36  C, C++, Artificial Intelligence, Python, Php, ...   \n",
       "37  Relationship Management, Retail Sales, Private...   \n",
       "38                 Data Science, Software Engineering   \n",
       "39  Data Science, Big Data Analytics, Digital Mark...   \n",
       "40                  Data Science, Recruitment, Salary   \n",
       "41  B.Tech, Tableau, Statistics, R, Analytics, Tim...   \n",
       "42  Software Development, Business Intelligence, B...   \n",
       "43                   Data Science, Node.js, Angularjs   \n",
       "44  Data Science, Media Marketing, Resource Planni...   \n",
       "45  Data Analysis, Learning, Data Science, Compute...   \n",
       "46  Java, Hadoop, R, Machine Learning, Spark, Flum...   \n",
       "47  Software Development, Core Java, Unit Testing,...   \n",
       "48  Machine Learning, Data Science, Product Manage...   \n",
       "49  Data Science, Machine Learning, Big Data Analy...   \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                       Pune  \n",
       "3                  Ahmedabad  \n",
       "4              UK - (london)  \n",
       "5          Vadodara / Baroda  \n",
       "6                    Chennai  \n",
       "7                 Trivandrum  \n",
       "8                     Indore  \n",
       "9      Bengaluru / Bangalore  \n",
       "10                 Hyderabad  \n",
       "11  Hyderabad / Secunderabad  \n",
       "12     Bengaluru / Bangalore  \n",
       "13                    Mumbai  \n",
       "14                    Mumbai  \n",
       "15  Hyderabad / Secunderabad  \n",
       "16                    Bhopal  \n",
       "17                Chandigarh  \n",
       "18                      Pune  \n",
       "19               Navi Mumbai  \n",
       "20                    Cochin  \n",
       "21                     Delhi  \n",
       "22  Hyderabad / Secunderabad  \n",
       "23                      Pune  \n",
       "24                      Pune  \n",
       "25                      Pune  \n",
       "26                      Pune  \n",
       "27     Bengaluru / Bangalore  \n",
       "28     Bengaluru / Bangalore  \n",
       "29                         -  \n",
       "30                     Delhi  \n",
       "31     Bengaluru / Bangalore  \n",
       "32           Mysoru / Mysore  \n",
       "33  Hyderabad / Secunderabad  \n",
       "34     Bengaluru / Bangalore  \n",
       "35                 New Delhi  \n",
       "36                   Chennai  \n",
       "37                   Aligarh  \n",
       "38            Salt Lake City  \n",
       "39                      Pune  \n",
       "40     Bengaluru / Bangalore  \n",
       "41                    Mumbai  \n",
       "42                    Indore  \n",
       "43     Bengaluru / Bangalore  \n",
       "44                    MYSORE  \n",
       "45  Hyderabad / Secunderabad  \n",
       "46     Bengaluru / Bangalore  \n",
       "47                    Mumbai  \n",
       "48                         -  \n",
       "49  Hyderabad / Secunderabad  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':name,'Designation':designation,'Skills':skills,'Location':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca05a9df",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b73a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731134a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5710e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8962a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0d00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=[]\n",
    "book=driver.find_element(By.XPATH,'//td[@id=\"table-cell-10943-0-1\"]')\n",
    "book_name.append(book.text)\n",
    "\n",
    "author_name=[]\n",
    "author=driver.find_element(By.XPATH,'//td[@id=\"table-cell-10943-0-2\"]')\n",
    "author_name.append(author.text)\n",
    "\n",
    "volume_sold=[]\n",
    "volume=driver.find_element(By.XPATH,'//td[@id=\"table-cell-10943-0-3\"]')\n",
    "volume_sold.append(volume.text)\n",
    "\n",
    "publisher=[]\n",
    "pub=driver.find_element(By.XPATH,'//td[@id=\"table-cell-10943-0-4\"]')\n",
    "publisher.append(pub.text)\n",
    "\n",
    "genre=[]\n",
    "g=driver.find_element(By.XPATH,'//td[@id=\"table-cell-10943-0-5\"]')\n",
    "genre.append(g.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9a8d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Book Name Author Name Volume Sold   Publisher  \\\n",
       "0  Da Vinci Code,The  Brown, Dan   5,094,805  Transworld   \n",
       "\n",
       "                         Genre  \n",
       "0  Crime, Thriller & Adventure  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Book Name':book_name,'Author Name':author_name,'Volume Sold':volume_sold,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4523a78",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456424dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58223ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efe46807",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_title=[]\n",
    "list_=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in list_[0:100]:\n",
    "    title=i.text.split()\n",
    "    list_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30d273a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_=[]\n",
    "n=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in n[0:100]:\n",
    "    n1=i.text.split()[1:-1]\n",
    "    name_.append(n1)\n",
    "    \n",
    "year_span=[]\n",
    "y=driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in y[0:100]:\n",
    "    y1=i.text\n",
    "    year_span.append(y1)\n",
    "    \n",
    "genre_=[]\n",
    "g=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in g[0:100]:\n",
    "    g1=i.text\n",
    "    genre_.append(g1)\n",
    "    \n",
    "run_time=[]\n",
    "r=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in r[0:100]:\n",
    "    r1=i.text\n",
    "    run_time.append(r1)\n",
    "    \n",
    "ratings=[]\n",
    "rating=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')\n",
    "for i in rating[0:100]:\n",
    "    rat1=i.text\n",
    "    ratings.append(rat1)\n",
    "    \n",
    "votes=[]\n",
    "v=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in v[0:100]:\n",
    "    v1=i.text\n",
    "    votes.append(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6f30ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(name_),len(year_span),len(genre_),len(run_time),len(ratings),len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "783a4c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Game, of, Thrones]</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,047,798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Stranger, Things, (2016–]</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,144,171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Walking, Dead]</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>967,852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13, Reasons, Why]</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>288,737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, 100]</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>248,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[Reign]</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[A, Series, of, Unfortunate, Events]</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Criminal, Minds]</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>194,718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Scream:, The, TV, Series]</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[The, Haunting, of, Hill, House]</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>236,269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name    Year Span  \\\n",
       "0                    [Game, of, Thrones]  (2011–2019)   \n",
       "1             [Stranger, Things, (2016–]     (2016– )   \n",
       "2                   [The, Walking, Dead]  (2010–2022)   \n",
       "3                     [13, Reasons, Why]  (2017–2020)   \n",
       "4                             [The, 100]  (2014–2020)   \n",
       "..                                   ...          ...   \n",
       "95                               [Reign]  (2013–2017)   \n",
       "96  [A, Series, of, Unfortunate, Events]  (2017–2019)   \n",
       "97                     [Criminal, Minds]  (2005–2020)   \n",
       "98            [Scream:, The, TV, Series]  (2015–2019)   \n",
       "99      [The, Haunting, of, Hill, House]       (2018)   \n",
       "\n",
       "                       Genre Run Time Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.2  2,047,798  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7  1,144,171  \n",
       "2    Drama, Horror, Thriller   44 min     8.1    967,852  \n",
       "3   Drama, Mystery, Thriller   60 min     7.5    288,737  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    248,307  \n",
       "..                       ...      ...     ...        ...  \n",
       "95                     Drama   42 min     7.4     49,540  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     60,545  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    194,718  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     41,013  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    236,269  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':name_,'Year Span':year_span,'Genre':genre_,'Run Time':run_time,'Ratings':ratings,'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66531938",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eabf45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44b1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b501c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=driver.find_element(By.XPATH,'/html/body/table[1]/tbody/tr/td[2]/span[2]')\n",
    "c1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b597cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "n=driver.find_elements(By.XPATH,'//p[@class=\"normal\"]/b')\n",
    "for i in n[0:622]:\n",
    "    n1=i.text\n",
    "    name.append(n1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0186b34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Average Localization Error (ALE) in sensor node localization process in WSNs',\n",
       " '9mers from cullpdb',\n",
       " 'TamilSentiMix',\n",
       " 'Accelerometer',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Pedal Me Bicycle Deliveries',\n",
       " 'Turkish Headlines Dataset',\n",
       " 'Secondary Mushroom Dataset',\n",
       " 'Power consumption of Tetouan city',\n",
       " 'Raisin Dataset',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Gender Gap in Spanish WP',\n",
       " 'Non verbal tourists data',\n",
       " 'Roman Urdu Sentiment Analysis Dataset (RUSAD)',\n",
       " 'TUANDROMD ( Tezpur University Android Malware Dataset)',\n",
       " 'Higher Education Students Performance Evaluation Dataset',\n",
       " 'Risk Factor prediction of Chronic Kidney Disease',\n",
       " 'Lab Test',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'Rocket League Skillshots Data Set',\n",
       " 'Sepsis survival minimal clinical records',\n",
       " 'Water Quality Prediction',\n",
       " 'Traffic Flow Forecasting',\n",
       " 'sentiment analysis in Saudi Arabia about distance education during Covid-19',\n",
       " 'Kain Tradisional Sambas',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing',\n",
       " 'REWEMA',\n",
       " 'REJAFADA',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Influenza outbreak event prediction via Twitter data',\n",
       " 'Turkish Music Emotion Dataset',\n",
       " 'Maternal Health Risk Data Set',\n",
       " 'Room Occupancy Estimation',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6d9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
